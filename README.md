## Welcome to STATS 701 WI 2021

This is a special topics course on the Theory of Reinforcement Learning (RL). We will focus on the design and analysis of RL algorithms using tools from regret analysis of online algorithms, concentration inequalities, and stochastic approximation. The "core" of this course will be based on online RL in a finite state-action (often called the "tabular" setting) Markov Decision Process (MDP) and will be taught in traditional lecture style (fully remote due to COVID-19). The "advanced" part of this course will choose topics based on audience interest and will be more discussion based. Students will volunteer to read a paper (or a small group of related papers) and lead its discussion in the class. Topics for the advanced part could include:

- RL with function approximation (from simple cases like linear functions to more difficult cases like deep RL)
- continuous state and action spaces (e.g., LQR systems \[linear systems with quadratic costs\])
- offline and off-policy evaluation
- multi-task and transfer learning in RL
- topics related to the above (e.g., lifelong RL, meta RL)
- hierarchical RL
- multi-agent RL

We will use the following resources:
- for the core part: [course notes by Prof. Vidyasagar](https://www.iith.ac.in/~m_vidyasagar/RL/Gen/) and [the boot camp](https://simons.berkeley.edu/workshops/schedule/14378) from the Simons Institute Fall 2020 program on the Theory of Reinforcement Learning
- for the advanced part: the three workshops from the Simons Theory of RL program ([deep RL](https://simons.berkeley.edu/workshops/schedule/14238), [online RL](https://simons.berkeley.edu/workshops/schedule/14239), [RL using batch/simulation data](https://simons.berkeley.edu/workshops/schedule/14240))  
- for more resources, look [here](resources.md)

The course is aimed at advanced graduate students in statistics, computer science, control theory, operations research, and other related disciplines that study sequential decision making under uncertainty. Prior exposure to RL (or at least MDPs) is strongly recommended. This course has a theoretical/mathematical flavor and therefore mathematical maturity is expected.

## Instructor Information

**Name**: Ambuj Tewari  
**Zoom Office Hours**: By appointment  
**Email**: tewaria@umich.edu  

## Grading

There will be no graded homeworks or exams. Grades will be determined on the basis of class presentations and a final project.

## Schedule 

Lecture No. | Date | Topic | Readings
--- | --- | --- | ---
01 | Jan 19 | Introduction | --
02 | Jan 21 | -- | --
03 | Jan 26 | -- | --
04 | Jan 28 | -- | --
05 | Feb 02 | -- | --
06 | Feb 04 | -- | --
07 | Feb 09 | -- | --
08 | Feb 11 | -- | --
09 | Feb 16 | -- | --
10 | Feb 18 | -- | --
11 | Feb 23 | -- | --
12 | Feb 25 | -- | --
13 | Mar 02 | <span style="color:red">Proposals due</span> | --
14 | Mar 04 | -- | --
15 | Mar 09 | -- | --
16 | Mar 11 | -- | --
17 | Mar 16 | -- | --
18 | Mar 18 | -- | --
-- | Mar 23 | Well-being break | --
19 | Mar 25 | -- | --
20 | Mar 30 | -- | --
21 | Apr 01 | -- | --
22 | Apr 06 | -- | --
23 | Apr 08 | -- | --
24 | Apr 13 | -- | --
25 | Apr 15 | -- | --
26 | Apr 20 | -- | --
